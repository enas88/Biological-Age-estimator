{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Version of Biological Age Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, corrcoef, array\n",
    "import math\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "from sklearn import datasets, linear_model\n",
    "#import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BIOLOGICAL AGE ALGORITHM\\nNOTE: RUN IN ANACONDA FOR PYTHON 2.7 ONLY\\n\\nHow to use commands:\\n- Create an instance of the data, then apply methods.\\n\\t- e.g. To find means, use Summary(dataset).mean()\\n\\nClasses:\\nSummary:\\n\\tMethods: \\n\\t.mean() [calculates mean]\\n\\t.corr(col1, col2) [calculates Pearson's Corr Coefficient & p-value] *col2 can be a list or one column. Both parameters are OPTIONAL\\n\\t.view [shows data as a dataframe]\\nMethods:\\n\\tMethods:\\n\\t.KDM() [gives Klemera & Doubal equation for biological age]\\n\\t.cleandata(col1,col2) [gets rid of all rows with missing values]\\n\\t.calcLR() [calculates linear regressions of all vars with age as predictor]\\nVisualize:\\n\\t.plot(X,Y,[stratifying_variable]) [view plot of biological age vs chronological age]\\n\\t.view [analyze data frame output]\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"BIOLOGICAL AGE ALGORITHM\n",
    "NOTE: RUN IN ANACONDA FOR PYTHON 2.7 ONLY\n",
    "\n",
    "How to use commands:\n",
    "- Create an instance of the data, then apply methods.\n",
    "\t- e.g. To find means, use Summary(dataset).mean()\n",
    "\n",
    "Classes:\n",
    "Summary:\n",
    "\tMethods: \n",
    "\t.mean() [calculates mean]\n",
    "\t.corr(col1, col2) [calculates Pearson's Corr Coefficient & p-value] *col2 can be a list or one column. Both parameters are OPTIONAL\n",
    "\t.view [shows data as a dataframe]\n",
    "Methods:\n",
    "\tMethods:\n",
    "\t.KDM() [gives Klemera & Doubal equation for biological age]\n",
    "\t.cleandata(col1,col2) [gets rid of all rows with missing values]\n",
    "\t.calcLR() [calculates linear regressions of all vars with age as predictor]\n",
    "Visualize:\n",
    "\t.plot(X,Y,[stratifying_variable]) [view plot of biological age vs chronological age]\n",
    "\t.view [analyze data frame output]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CLASS SUMMARY #######################\n",
    "\n",
    "#Double check means\n",
    "#Make a dictionary of the means of each thing, turn into a function\n",
    "class Summary(object):\n",
    "    def __init__(self, dataframe, age, samp_wtIndex, primarykey):\n",
    "        header_names = list(dataframe)\n",
    "        temp = dataframe.values.tolist()\n",
    "        temp.insert(0, header_names)\n",
    "        \n",
    "        self.primarykey = primarykey\n",
    "        self.data = temp\n",
    "        self.view = dataframe\n",
    "        self.age = age\n",
    "        self.samp_wt = samp_wtIndex\n",
    "\n",
    "    def mean(self, lowerboundage=0, upperboundage=999):\n",
    "        avgdict = {}\n",
    "        floatdum = 3.0\n",
    "        # cols 0 - 16\n",
    "        for col in range(len(self.data[0])):\n",
    "            avglist = []\n",
    "            sampwtlist = []\n",
    "            \n",
    "            if col == self.primarykey:\n",
    "                continue\n",
    "            \n",
    "            for line in self.data[1:]:\n",
    "\n",
    "                if line[self.age] >= lowerboundage and line[self.age] <= upperboundage and type(line[col]) == type(floatdum):\n",
    "                    avglist.append(line[col])\n",
    "                    sampwtlist.append(line[self.samp_wt])\n",
    "                \n",
    "            avgdict[self.data[0][col]] = np.mean(avglist) #sum([i * j for i,j in zip(avglist, sampwtlist)])/len(avglist)\n",
    "\n",
    "        self.make_pretty(avgdict,\"MEANS:\")\n",
    "        return avgdict\n",
    "\n",
    "    #returns a pretty row of results\n",
    "    def make_pretty(self,dictionary,titlestring):\n",
    "        print(\"\\n\" + titlestring)\n",
    "        keylist = sorted(dictionary.keys())\n",
    "        for key in keylist:\n",
    "            if len(key) < 8 :\n",
    "                print(key + '\\t\\t' + str(dictionary[key]))\n",
    "            else:\n",
    "                print(key + '\\t' + str(dictionary[key]))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"There are {} observations and {} variables in this dataset.\".format(len(self.data),len(self.data[0]))\n",
    "\n",
    "    #returns the Pearson Correlation coefficient of each row in the dataset to a variable\n",
    "    #input parameters: column number of you want to compare to. Second one to compare to\n",
    "    #first value can only be one value. If you put a #<0 for y, will be a list of all vals. default is all vals\n",
    "    def corr(self, x=-2, y=-1):\n",
    "        corrdict = {}\n",
    "        repeat = False\n",
    "        #establishes what we'll be correlating to x\n",
    "        if y >= 0:\n",
    "            collist = [y]\n",
    "        elif y < 0:\n",
    "            collist = range(len(self.data[0]))\n",
    "        else:\n",
    "            print(\"Please enter a valid input\")\n",
    "            quit()\n",
    "\n",
    "        for col in collist:\n",
    "            corrlistx = []\n",
    "            corrlisty= []\n",
    "            for line in self.data:\n",
    "                if type(line[x]) == type(1.2):\n",
    "                    corrlistx.append(line[x])\n",
    "                elif type(line[x]) != type(1.2):\n",
    "                    corrlistx.append('.')\n",
    "\n",
    "                if type(line[col]) == type(1.2):\n",
    "                    corrlisty.append(line[col])\n",
    "                else:\n",
    "                    corrlisty.append('.')\n",
    "\n",
    "            try:\n",
    "                corrdict[self.data[0][col]] = stats.pearsonr(*self.findmissing(corrlistx,corrlisty))\n",
    "            except:\n",
    "                print(\"Cannot perfom correlation on\", self.data[0][col])\n",
    "\n",
    "        self.make_pretty(corrdict,\"CORRELATIONS: (r, p-value)\")\n",
    "        return corrdict\n",
    "\n",
    "    #throws away values where at least one value is missing\n",
    "    def findmissing(self,corrlist1,corrlist2):\n",
    "        for i in range(len(corrlist1)):\n",
    "            try:\n",
    "                if corrlist1[i] != type(1.2):\n",
    "                    del corrlist1[i]\n",
    "                    del corrlist2[i]\n",
    "            except: pass\n",
    "\n",
    "        for i in range(len(corrlist2)):\n",
    "            try:\n",
    "                if corrlist2[i] != type(1.2):\n",
    "                    del corrlist1[i]\n",
    "                    del corrlist2[i]\n",
    "            except: pass\n",
    "        return (corrlist1, corrlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################## CLASS METHODS #######################\n",
    "class Methods(object):\n",
    "    def __init__(self, dataframe, cache_fname, age, genderindex, primarykey, samp_wt, output):\n",
    "        # convert DataFrame to List Format\n",
    "        header_names = list(dataframe)\n",
    "        temp = dataframe.values.tolist()\n",
    "        temp.insert(0, header_names)\n",
    "        \n",
    "        self.data = temp\n",
    "        self.age = age\n",
    "        self.genderindex = genderindex\n",
    "        self.primarykey = primarykey\n",
    "        self.samp_wt= samp_wt\n",
    "        self.cache_fname = cache_fname\n",
    "        #print(\"Looking for data in cache...\")\n",
    "        try:\n",
    "            cache_fhnd = open(self.cache_fname,'r')\n",
    "            self.CACHE_DICT = json.loads(cache_fhnd.read())\n",
    "            cache_fhnd.close()\n",
    "        except:\n",
    "            self.CACHE_DICT = {}\n",
    "        self.AGEON = True # age corrector toggle\n",
    "        self.GRAPHON = True # do you want to see linear regression graphs for each variable on age?\n",
    "        self.savepath = output\n",
    "        \n",
    "        # determine how groups there are\n",
    "        self.GroupSet = pd.unique(dataframe[header_names[self.genderindex]].values).astype('int')\n",
    "\n",
    "        if len(self.GroupSet) > 2:\n",
    "            raise ValueError('There are more than 2 groups in this dataset')\n",
    "\n",
    "###############################################################################################\n",
    "########################## Klemera and Doubal Method ##########################################\n",
    "###############################################################################################\n",
    "\n",
    "#Note on CACHE_DICT vs cachedict: CACHE_DICT is the \"global local\" variable for the instance. cachedict is input as a parameter if the value is in CACHE_DICT\n",
    "    def KDM(self):\n",
    "        #have this one combine the two datasets, for men and for women\n",
    "        #and append to a list\n",
    "        finaldict = {}\n",
    "\n",
    "        for sex in self.GroupSet:\n",
    "            if sex == 0:\n",
    "                sexname = \"Males\"\n",
    "            else: sexname = \"Females\"\n",
    "\n",
    "            if str(sex) in self.CACHE_DICT:\n",
    "                #print(\"Collecting parameters from cache for %s...\" % (sexname))\n",
    "                self.calcLR(sex=sex,cachedict = self.CACHE_DICT[str(sex)]) #finds self.regressiondict and makes self.newdata\n",
    "                finaldict[sex] = self.calcBA(correctiondict = self.correctionterm(self.calcBA()))\n",
    "            else:\n",
    "                #print(\"Could not find parameters in the cache for %s...\" % (sexname))\n",
    "                self.calcLR(sex=sex) #makes self.regressiondict\n",
    "                finaldict[sex] = self.calcBA(correctiondict = self.correctionterm(self.calcBA()))\n",
    "\n",
    "        #print(\"Merging data one last time...\")\n",
    "        #Double check this...\n",
    "        if 'BA' not in self.data[0]:\n",
    "            for row in self.data:\n",
    "                for sexkey in finaldict: #going through each SEQN\n",
    "                    for key in finaldict[sexkey]:\n",
    "                        if key == row[self.primarykey]:          #if you found the right SEQN for that row, append the Corrected Biological Age to the end\n",
    "                            row.append(finaldict[sexkey][key])\n",
    "        if 'BA' not in self.data[0]:\n",
    "            self.data[0].append('BA')\n",
    "        if 'BAC' not in self.data[0]:\n",
    "            self.data[0].append('BAC')\n",
    "\n",
    "        #print(\"DONE!\")\n",
    "\n",
    "        path = self.savepath\n",
    "        fopen = open(path,'w+')\n",
    "        \n",
    "        #print(\"Saving Data...\")\n",
    "        for row in self.data:\n",
    "            for i in range(len(row)):\n",
    "                row[i] = str(row[i])\n",
    "            fopen.write(\",\".join(row) + \"\\n\")\n",
    "\n",
    "    #   fopen.write(json.dumps(finaldict))\n",
    "        fopen.close()\n",
    "        #print(\"DONE!\")\n",
    "        return self.data\n",
    "\n",
    "    #REMEMBER TO CONSIDER SEX IN THIS...CALCLR CALCULATES FOR ONLY ONE SEX AT A TIME BUT YOU NEED A DICTIONARY THAT ACCOUNTS FOR BOTH\n",
    "    #this uses the regression results to create all the baseline variables for KDM calculations\n",
    "    def correctionterm(self, datatuple, agemax = 24, agemin = 36): # changed months to 2-3 years\n",
    "        m = datatuple[1] #this tells you how many covariates we have\n",
    "        BAdict = datatuple[0] #this was BasicBAdict from the calcBA function\n",
    "        n = len(self.newdata)-1\n",
    "        delcounter = 0\n",
    "\n",
    "        CorrectedBAdict = {}\n",
    "        \n",
    "        #Merge BAdict with self.newdata (remember, this is the dataset with only one sex)\n",
    "        #print(\"Merging data...\")\n",
    "        for row in self.newdata:\n",
    "            try:\n",
    "                row.append(BAdict[row[self.primarykey]][0]) #will append to the end of the row the BA value from the dictionary, using the primary key as the identifier\n",
    "            except:\n",
    "                del(row)\n",
    "                delcounter += 1\n",
    "\n",
    "        if delcounter > 0: \n",
    "            print(\"Warning: %d rows deleted. Check the integrity of the data or check the code.\" % (delcounter))\n",
    "\n",
    "        #STANDARD DEVIATION CALCULATIONS\n",
    "        #Calculating first term\n",
    "        errcalc  = []\n",
    "        #print(\"Calculating Correction Term...\")\n",
    "        for row in self.newdata:\n",
    "            BA = row[-1] #the last value appended to each row\n",
    "            errcalc.append(BA - row[self.age])\n",
    "        errcalc = np.array(errcalc)\n",
    "        #Calculating standard deviation\n",
    "\n",
    "        for row in self.newdata:\n",
    "            rchar = BAdict[row[self.primarykey]][1]\n",
    "            stderr = (np.var(errcalc) - (((1-(rchar**2))/(rchar**2)) * (((agemax - agemin)**2)/(12*m))))\n",
    "            \n",
    "            # Extra step: Linearly transform so that SBA maintains same mean but now linearly increases with age, so difference is 5 between CAmax and CAmin\n",
    "            if self.AGEON == True:\n",
    "                agecorrector = 5/(agemax-agemin)\n",
    "                std = np.sqrt(stderr) - 2.5 + (agecorrector * row[self.age]) # adjust based on age\n",
    "                stderr = std ** 2\n",
    "                #print(stderr)\n",
    "\n",
    "            CorrectedBAdict[row[self.primarykey]] = stderr\n",
    "\n",
    "        return CorrectedBAdict\n",
    "    #############\n",
    "    def cov(self, x, y, w):\n",
    "        \"\"\"Weighted Covariance\"\"\"\n",
    "        return np.sum(w * (x - np.average(x, weights = w)) * (y - np.average(y, weights = w))) / np.sum(w)\n",
    "\n",
    "    def corr(self, x, y, w):\n",
    "        \"\"\"Weighted Correlation\"\"\"\n",
    "        return self.cov(x, y, w) / np.sqrt(self.cov(x, x, w) * self.cov(y, y, w))\n",
    "    #############\n",
    "\n",
    "    #This takes all the data from the Linear Regression function and calcuates the baseline predicted age and rchar.\n",
    "    #It then passes all the variables to correctionterm method (if you use the .KDM() method), which will aggregate these variables into calculating the corrected BA.\n",
    "    def calcBA(self, correctiondict={}):\n",
    "        #append another value to the end of each row?\n",
    "        BasicBAdict = {}\n",
    "        CorrectedBAdict = {}\n",
    "\n",
    "        if correctiondict == {}:\n",
    "            #print(\"Calculating initial BA without Correction...\")\n",
    "            for row in self.newdata:\n",
    "                numeratorlist = []\n",
    "                denominatorlist = []\n",
    "                rcharlistnumerator = []\n",
    "                rcharlistdenominator = []\n",
    "            #append BA data to each row\n",
    "                for key in self.regressiondict:\n",
    "                #append numerators to a list and denominators to a list, then sum and divide\n",
    "                    covar = self.regressiondict[key] #references one column or variable in study\n",
    "                    k = covar[0] #slope\n",
    "                    s = covar[3] #MSE\n",
    "                    q = covar[1] #intercept\n",
    "                    r = covar[2] #r-value\n",
    "\n",
    "                    colindex = self.heading.index(key) #find the column of the data\n",
    "\n",
    "                    try:\n",
    "                        numeratorlist.append((row[colindex]-q)*(k/(s**2)))\n",
    "                        denominatorlist.append((k/s)**2)\n",
    "                        rcharlistnumerator.append(((r**2)/(math.sqrt(1-(r**2)))))\n",
    "                        rcharlistdenominator.append((r/(math.sqrt(1-(r**2)))))\n",
    "                    except:\n",
    "                        print(\"r:\",r, \"var:\", key)\n",
    "                        #print(self.regressiondict)\n",
    "                        quit()\n",
    "                #rcalculations\n",
    "                rchar = sum(rcharlistnumerator)/sum(rcharlistdenominator)\n",
    "                #create a dictionary with SEQN as key\n",
    "\n",
    "                ####################print((sum(numeratorlist)/sum(denominatorlist), rchar))\n",
    "                BasicBAdict[row[self.primarykey]] = (sum(numeratorlist)/sum(denominatorlist), rchar)\n",
    "            #returns a tuple with dictionary first, m second\n",
    "            return (BasicBAdict,len(self.regressiondict))\n",
    "        else:\n",
    "            #print(\"Calculating final Age with Corrected Values...\")\n",
    "            for row in self.newdata:\n",
    "                numeratorlist = []\n",
    "                denominatorlist = []\n",
    "\n",
    "                #append BA data to each row\n",
    "                for key in self.regressiondict:\n",
    "                #append numerators to a list and denominators to a list, then sum and divide\n",
    "                    covar = self.regressiondict[key] #references one column or variable in study\n",
    "                    k = covar[0] #slope\n",
    "                    s = covar[3] #MSE\n",
    "                    q = covar[1] #intercept\n",
    "                    r = covar[2] #r-value\n",
    "                    colindex = self.heading.index(key) #find the column of the data\n",
    "\n",
    "                    numeratorlist.append((row[colindex]-q)*(k/(s**2))+(row[self.age]/correctiondict[row[self.primarykey]]))\n",
    "                    denominatorlist.append(((k/s)**2)+(1/correctiondict[row[self.primarykey]]))\n",
    "\n",
    "                #create a dictionary with SEQN as key\n",
    "\n",
    "                CorrectedBAdict[row[self.primarykey]] = sum(numeratorlist)/sum(denominatorlist)\n",
    "            #returns a final dictionary of Corrected BA\n",
    "            return CorrectedBAdict\n",
    "\n",
    "\n",
    "\n",
    "    #remember female = 1, means female\n",
    "    #this does the inital linear regressions: MODEL xx = age\n",
    "    def calcLR(self, sex=0, cachedict = {}):\n",
    "        #creates a new dataset for ONLY females or only males\n",
    "        self.newdata = [line for line in self.data if line[self.genderindex] == \"\" or line[self.genderindex] == sex]\n",
    "        self.df = pd.DataFrame(self.newdata[1:],columns=self.data[0])\n",
    "        self.heading = list(self.df)\n",
    "        self.regressiondict = {} #saves tuple: (slope,intercept,r_value,std_err)\n",
    "        if sex == 0:\n",
    "            sexname = \"Males\"\n",
    "        else:\n",
    "            sexname = \"Females\"\n",
    "        #check if there is already a value in cachedict:\n",
    "        if cachedict == {}:\n",
    "            #print(\"Calculating regressions for %s...\" % (sexname))\n",
    "        \n",
    "\n",
    "            # REGRESSION PART #\n",
    "            for idx,col in enumerate(self.heading):\n",
    "                #print(col)\n",
    "                if idx in [self.age, self.primarykey, self.genderindex, self.samp_wt]:\n",
    "                    continue\n",
    "                \n",
    "                regX = np.array(self.df[list(self.df)[self.age]]).reshape(-1, 1) #age\n",
    "                regY = np.array(self.df[[col]]) #other var\n",
    "\n",
    "                regr = linear_model.LinearRegression()\n",
    "\n",
    "                try:\n",
    "                # Train the model using the training sets\n",
    "                    weight = np.array(self.get_column(self.samp_wt)).reshape(len(self.get_column(self.samp_wt)),1)\n",
    "\n",
    "                    regr.fit(regX,regY,sample_weight=self.get_column(self.samp_wt))\n",
    "                    #print regr.get_params(deep=False)\n",
    "\n",
    "                    #The coefficients\n",
    "                    #print 'Coefficients: \\n', regr.coef_\n",
    "                    #print 'Intercept: \\n', regr.intercept_\n",
    "        \n",
    "                    # The mean squared error\n",
    "                    #print \"Mean squared error: %.2f\" % mean((regr.predict(regX) - regY) ** 2) #MSE\n",
    "                    # Explained variance score: 1 is perfect prediction\n",
    "                    #print 'Variance score: %.2f' % (regr.score(regX, regY)) #variance\n",
    "                    #need slope, intercept, r-value\n",
    "\n",
    "                    # Plot outputs\n",
    "                    if self.GRAPHON == True:\n",
    "                        plt.scatter(regX, regY,  color='black')\n",
    "                        plt.plot(regX, regr.predict(regX), color='blue', linewidth=3)\n",
    "                        plt.xticks(())\n",
    "                        plt.yticks(())\n",
    "                        plt.title('%s vs Age' % (col))\n",
    "                        plt.xlabel('age')\n",
    "                        plt.ylabel(col)\n",
    "                        plt.show()\n",
    "\n",
    "                    #do linear regressions analysis\n",
    "                    slope = regr.coef_[0][0]\n",
    "                    intercept = regr.intercept_[0]\n",
    "                    # weighted vs unweighted corr seems to make no difference\n",
    "                    r_value = self.corr(regX, regY, weight) #stats.pearsonr(regX,regY)[0][0]\n",
    "                    std_err = math.sqrt(mean((regr.predict(regX) - regY) ** 2))\n",
    "                    #print(slope, intercept, r_value, std_err)\n",
    "\n",
    "                except:\n",
    "                    print(\"Cannot do LINEAR REGRESSION analysis for %s\" % (col))\n",
    "                    slope = 0\n",
    "                    intercept = 0\n",
    "                    r_value = 0\n",
    "                    std_err = 0\n",
    "\n",
    "                #CHECK THAT ONLY PROPER VALUES ARE ADDED\n",
    "                if slope and intercept and r_value and std_err != 0:\n",
    "                    #add to dictionaries\n",
    "                    self.regressiondict[col] = (slope, intercept, r_value, std_err)\n",
    "\n",
    "\n",
    "\n",
    "            #add to cache\n",
    "            cache_fhnd = open(self.cache_fname,'w')\n",
    "            self.CACHE_DICT[str(sex)] = self.regressiondict\n",
    "            cache_fhnd.write(json.dumps(self.CACHE_DICT))\n",
    "            cache_fhnd.close()\n",
    "        #if there is, make it into self.regressiondict\n",
    "        else:\n",
    "            self.regressiondict = cachedict\n",
    "        #self.make_pretty(self.regressiondict,\"REGRESSION VALUES (slope, intercept, r_value, std_err)\")\n",
    "        return self.regressiondict\n",
    "\n",
    "\n",
    "### Utility Functions ###\n",
    "\n",
    "    #returns the mean of each row in the dataset\n",
    "    def make_pretty(self,dictionary,titlestring):\n",
    "        print(\"\\n\" + titlestring)\n",
    "        keylist = sorted(dictionary.keys())\n",
    "        for key in keylist:\n",
    "            if len(key) < 8 :\n",
    "                print(key + '\\t\\t' + str(dictionary[key]))\n",
    "            else:\n",
    "                print(key + '\\t' + str(dictionary[key]))\n",
    "\n",
    "    #extracts one column from the dataset\n",
    "    def get_column(self,col):\n",
    "        column = [line[col] for line in self.newdata]\n",
    "        return column[1:]\n",
    "\n",
    "    #throws away values where at least one value is missing\n",
    "    def cleandata(self,col1,col2):\n",
    "        for i in range(len(col1)):\n",
    "            try:\n",
    "                if col1[i] != type(1.2):\n",
    "                    del col1[i]\n",
    "                    del col2[i]\n",
    "            except: pass\n",
    "\n",
    "        for i in range(len(col2)):\n",
    "            try:\n",
    "                if col2[i] != type(1.2):\n",
    "                    del col1[i]\n",
    "                    del col2[i]\n",
    "            except: pass\n",
    "        if len(col1) == len(col2):\n",
    "        #   print \"Dimensions match for both columns\"\n",
    "            return (col1, col2)\n",
    "        else:\n",
    "            print(\"Cannot match data by length, check data dimensions.\")\n",
    "            return (len(col1), len(col2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualize(object):\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "\n",
    "    def view(self):\n",
    "        return self.data\n",
    "\n",
    "    def plot(self, inp1, inp2, inp3): # (y, x, color by)\n",
    "        new_df = pd.DataFrame()\n",
    "\n",
    "        new_df[inp1] = pd.to_numeric(self.data[inp1])\n",
    "        new_df[inp2] = pd.to_numeric(self.data[inp2])\n",
    "        new_df[inp3] = self.data[inp3]\n",
    "\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        \n",
    "        for group in pd.unique(new_df[inp3]):\n",
    "            plt.scatter(new_df[new_df[inp3] == group][inp1], new_df[new_df[inp3] == group][inp2])\n",
    "        \n",
    "        ax.legend(pd.unique(new_df[inp3]))\n",
    "        plt.ylabel(inp1)\n",
    "        plt.xlabel(inp2)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDM_model(trainset, testset, cachename, output_filename, age_index, genderindex, primaryindex, samp_wt_index):\n",
    "\n",
    "    # Build model\n",
    "    output_filename_train = output_filename + 'train-missing.csv'\n",
    "    model = Methods(trainset, cachename, age = age_index, genderindex = genderindex, primarykey = primaryindex, samp_wt = samp_wt_index, output = output_filename_train)\n",
    "    model.KDM() # train model\n",
    "\n",
    "    # test using trained model\n",
    "    output_filename_test = output_filename + 'test-missing.csv'\n",
    "    test_model = Methods(testset, cachename, age = age_index, genderindex = genderindex, primarykey = primaryindex, samp_wt = samp_wt_index, output = output_filename_test)\n",
    "    results = test_model.KDM()\n",
    "    results = pd.DataFrame(results[1:], columns = results[0])\n",
    "\n",
    "    # calculate stats\n",
    "    stats = return_stats(results['BAC'].astype('float64'), results[list(results)[age_index]].astype('float64'))\n",
    "    \n",
    "    return (stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return statistics for a correlation\n",
    "def return_stats(x,y, dec=3):\n",
    "    slope, intercept, r_value, p_value, std_err = sp.stats.linregress(x,y)\n",
    "    \n",
    "    Mr = abs(x-y).mean()\n",
    "    Medr = np.median(abs(x-y))\n",
    "    Mpr = np.median(100*abs((x-y)/x))\n",
    "    rs = r_value**2\n",
    "    print(r_value)\n",
    "    \n",
    "    return(Mr, Medr, Mpr, p_value, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running BA_NB_Final at 2020-07-08 11:17:40.816938\n"
     ]
    }
   ],
   "source": [
    "print('You are running BA_NB_Final at', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'scipy.stats' from 'C:\\\\Users\\\\nosa\\\\Anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print (stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement bio_age (from versions: none)\n",
      "ERROR: No matching distribution found for bio_age\n"
     ]
    }
   ],
   "source": [
    "!pip install bio_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bio_age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-751f2b256bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbio_age\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mBA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bio_age'"
     ]
    }
   ],
   "source": [
    "import bio_age as BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
